<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Farnoush Rezaei Jafari</title> <meta name="author" content="Farnoush Rezaei Jafari"/> <meta name="description" content="My personal website."/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://farnoushrj.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> <script type="text/javascript">window.heap=window.heap||[],heap.load=function(e,t){window.heap.appid=e,window.heap.config=t=t||{};var r=document.createElement("script");r.type="text/javascript",r.async=!0,r.src="https://cdn.heapanalytics.com/js/heap-"+e+".js";var a=document.getElementsByTagName("script")[0];a.parentNode.insertBefore(r,a);for(var n=function(e){return function(){heap.push([e].concat(Array.prototype.slice.call(arguments,0)))}},p=["addEventProperties","addUserProperties","clearEventProperties","identify","resetIdentity","removeEventProperty","setEventProperties","track","unsetEventProperty"],o=0;o<p.length;o++)heap[p[o]]=n(p[o])},heap.load("2978544712");</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container-lg"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Farnoush</span> Rezaei Jafari </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/prof_pic-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/prof_pic-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/prof_pic-1400.webp"></source> <img class="img-fluid z-depth-1 rounded-circle" src="/assets/img/prof_pic.jpg" width="auto" height="auto" alt="prof_pic.jpg"> </picture> </figure> </div> <div class="clearfix"> <p>I am a doctoral researcher in the Machine Learning / Intelligent Data analysis group at Technische UniversitÃ¤t Berlin and BIFOLD (Berlin Institute for the Foundations of Learning and Data), working with <a href="https://scholar.google.com/citations?user=jplQac8AAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Prof. Dr. Klaus-Robert MÃ¼ller</a>. My primary focus lies in enhancing the interpretability and efficiency of machine learning models.</p> <p>Before embarking on my Ph.D. journey, I accomplished my M.Sc. in Computer Science at TU Berlin in the year 2021. I did my Masterâ€™s thesis, titled <em>â€œAnalyzing the Importance of Temporal Information in 3D ConvNets for Human Action Recognition Through Explanationsâ€</em> under the supervision of <a href="https://scholar.google.com/citations?user=jplQac8AAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Prof. Dr. Klaus-Robert MÃ¼ller</a> and <a href="https://scholar.google.com/citations?user=1CLaPMEAAAAJ" target="_blank" rel="noopener noreferrer">Prof. Dr. JÃ¼rgen Gall</a>.</p> </div> <div class="news"> <h2>news</h2> <div class="table-responsive" style="max-height: 100vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Mar 17, 2025</th> <td> ğŸ‰ I have been accepted into the <a href="https://www.matsprogram.org/" target="_blank" rel="noopener noreferrer">MATS</a> 8.0 Training Program, led by Neel Nanda. </td> </tr> <tr> <th scope="row">Jan 16, 2025</th> <td> ğŸ™ï¸ Invited talk at Microsoft ASG about our NeurIPS 2024 paper, <a href="https://nips.cc/virtual/2024/poster/96794" target="_blank" rel="noopener noreferrer">MambaLRP</a>. </td> </tr> <tr> <th scope="row">Jan 6, 2025</th> <td> ğŸ¥³ Our paper <a href="https://www.sciencedirect.com/science/article/pii/S1566253524007012" target="_blank" rel="noopener noreferrer">Towards Symbolic XAI</a> has got accepted at Information Fusion. </td> </tr> <tr> <th scope="row">Sep 27, 2024</th> <td> ğŸ‰ Our paper, <a href="https://nips.cc/virtual/2024/poster/96794" target="_blank" rel="noopener noreferrer">MambaLRP</a>, has got accepted at NeurIPS 2024. </td> </tr> <tr> <th scope="row">Aug 30, 2024</th> <td> ğŸ“¢ Check out our new preprint <a href="https://arxiv.org/abs/2408.17198" target="_blank" rel="noopener noreferrer">Towards Symbolic XAI</a>. </td> </tr> <tr> <th scope="row">Jun 11, 2024</th> <td> ğŸ“¢ Check out our new preprint on the interpretability of selective state space sequence models, called <a href="https://arxiv.org/pdf/2406.07592" target="_blank" rel="noopener noreferrer">MambaLRP</a>. </td> </tr> <tr> <th scope="row">Jul 3, 2022</th> <td> ğŸ¥³ Our paper, <a href="https://adaptivetokensampling.github.io/" target="_blank" rel="noopener noreferrer">ATS</a> is accepted at ECCV 2022 as an oral presentation. </td> </tr> <tr> <th scope="row">Jun 14, 2022</th> <td> ğŸ™ï¸ Presented our paper, <a href="https://adaptivetokensampling.github.io/" target="_blank" rel="noopener noreferrer">ATS</a> at Franco-German Workshop at Inria. </td> </tr> <tr> <th scope="row">Nov 17, 2021</th> <td> ğŸš€ I started my PhD journey. </td> </tr> </table> </div> </div> <div class="publications"> <h2>selected publications</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview" style="padding-top: 27px;"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/SymbXAI_logo.png" style="width: 100%"></div> <div class="col-sm-2 abbr position-absolute "><abbr class="badge" style="height: 20px;">Information Fusion</abbr></div> <div id="schnake2024symbolicxaiexplanation" class="col-sm-8"> <div class="title"> Towards Symbolic XAI â€“ Explanation Through Human Understandable Logical Relationships Between Features </div> <div class="author">Schnake, T.*,Â  <em>Rezaei Jafari, F.*</em>,Â Lederer, J,Â Xiong, P.,Â Nakajima, S.,Â Gugler, S.,Â Montavon, G.,Â and MÃ¼ller, K-R. </div> <div class="journal-name text-left"> <label class="journal-label"><em>Information Fusion</em> 2025</label> </div> <div> <b>* denotes equal contribution.</b> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.sciencedirect.com/science/article/pii/S1566253524007012" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p text-align: justify>Explainable Artificial Intelligence (XAI) plays a crucial role in fostering transparency and trust in AI systems. Traditional XAI methods typically provide a single level of abstraction for explanations, often in the form of heatmaps in post-hoc attribution methods. Alternatively, XAI offers rule-based explanations that are expressive and composed of logical formulas but often fail to faithfully capture the modelâ€™s decision-making process or impose strict limitations on the modelâ€™s learning capabilities by requiring it to be inherently self-explainable. We aim to bridge these two approaches by developing post-hoc explanations that attribute relevance to complex logical relationships between input features while faithfully aligning with the modelâ€™s intricate prediction processes and imposing no restrictions on the modelâ€™s architecture. To this end, we propose a framework called Symbolic XAI, which attributes relevance to symbolic formulas expressing logical relationships between input features. Our method naturally extends propagation-based explanation approaches, such as layer-wise relevance propagation or GNN-LRP, and perturbation-based approaches, such as Shapley-values. Beyond relevance attribution of logical formulas for a modelâ€™s prediction, our framework introduces a strategy to automatically identify logical formulas that best summarize the modelâ€™s decision strategy, eliminating the need to predefine these formulas. We demonstrate the effectiveness of our framework in domains such as natural language processing (NLP), computer vision, and chemistry, where abstract symbolic domain knowledge is abundant and critically valuable to users. In summary, the Symbolic XAI framework provides a local understanding of the modelâ€™s decision-making process that is both flexible for customization by the user and human-readable through logical formulas.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview" style="padding-top: 27px;"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/MambaLRP_logo.gif" style="width: 100%"></div> <div class="col-sm-2 abbr position-absolute "><abbr class="badge" style="height: 20px;">NeurIPS</abbr></div> <div id="jafari2024mambalrp" class="col-sm-8"> <div class="title"> MambaLRP: Explaining Selective State Space Sequence Models </div> <div class="author"> <em>Rezaei Jafari, F.</em>,Â Montavon, G.,Â MÃ¼ller, K-R.,Â and Eberle, O. </div> <div class="journal-name text-left"> <label class="journal-label"><em>Conference on Neural Information Processing Systems (NeurIPS)</em> 2024</label> </div> <div> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2406.07592" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/farnoushrj/mambalrp" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Website</a> </div> <div class="abstract hidden"> <p text-align: justify>We propose MambaLRP, a novel algorithm within the LRP framework, which ensures a more stable and reliable relevance propagation through these components. Our proposed method is theoretically sound and excels in achieving state-of-the-art explanation performance across a diverse range of models and datasets. Moreover, MambaLRP facilitates a deeper inspection of Mamba architectures, uncovering various biases and evaluating their significance. It also enables the analysis of previous speculations regarding the long-range capabilities of Mamba models.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview" style="padding-top: 27px;"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/ATS_logo.gif" style="width: 100%"></div> <div class="col-sm-2 abbr position-absolute "><abbr class="badge" style="height: 20px;">ECCV Oral</abbr></div> <div id="ATS" class="col-sm-8"> <div class="title"> Adaptive Token Sampling For Efficient Vision Transformers </div> <div class="author">Fayyaz, M.*,Â Abbasi Kouhpayegani, S.*,Â  <em>Rezaei Jafari, F.*</em>,Â Sengupta, S.,Â Sommerlade, E.,Â Vaezi Joze, H.,Â Pirsiavash, H.,Â and Gall, J. </div> <div class="journal-name text-left"> <label class="journal-label"><em>European Conference on Computer Vision (ECCV)</em> 2022</label> </div> <div> <b>* denotes equal contribution.</b> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2111.15667.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://adaptivetokensampling.github.io/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Website</a> </div> <div class="abstract hidden"> <p text-align: justify>In this work, we therefore introduce a differentiable parameter-free Adaptive Token Sampler (ATS) module, which can be plugged into any existing vision transformer architecture. ATS empowers vision transformers by scoring and adaptively sampling significant tokens. As a result, the number of tokens is not constant anymore and varies for each input image. By integrating ATS as an additional layer within the current transformer blocks, we can convert them into much more efficient vision transformers with an adaptive number of tokens. Since ATS is a parameter-free module, it can be added to the off-the-shelf pre-trained vision transformers as a plug and play module, thus reducing their GFLOPs without any additional training. Moreover, due to its differentiable design, one can also train a vision transformer equipped with ATS. We evaluate the efficiency of our module in both image and video classification tasks by adding it to multiple SOTA vision transformers. Our proposed module improves the SOTA by reducing their computational costs (GFLOPs) by 2 times, while preserving their accuracy on the ImageNet, Kinetics-400, and Kinetics-600 datasets.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%72%65%7A%61%65%69%6A%61%66%61%72%69@%63%61%6D%70%75%73.%74%75-%62%65%72%6C%69%6E.%64%65" title="email"><i class="fas fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=Ei7ny-IAAAAJ&amp;hl=en&amp;oi=sra" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/FarnoushRJ" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/farnoushrj" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a> <a href="https://twitter.com/FarnoushRJ" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a> </div> <div class="contact-note"> </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> Â© Copyright 2025 Farnoush Rezaei Jafari. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script async src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script> <script async src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script> <script async src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>